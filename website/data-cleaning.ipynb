{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: \"Data Cleaning\"\n",
        "format: html\n",
        "toc: true\n",
        "toc_depth: 3 \n",
        "number sections: true \n",
        "code-fold: show\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<b>*Disclaimer - this section is a work in progress</b>\n",
        "<br></br>\n",
        "This page shows the raw data, the code used to clean it, and the modified data. It's a journal of my data cleaning process. Please be aware that this page contains both Python and R code, thus you should avoid running the source code all at once."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseballr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ncaahoopR\n",
        "\n",
        "let's clean the Villanova 2021-22 data with R:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here is a screen shot of the first few rows and columns of the raw data:\n",
        "<br></br>\n",
        "![raw data](./images/villanova2122raw.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "library(tidyverse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# let's load in the data\n",
        "nova2122 <- read.csv('./data/raw_data/villanova2122.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>11405</li><li>39</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 11405\n",
              "\\item 39\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 11405\n",
              "2. 39\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] 11405    39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check the shape of the data\n",
        "dim(nova2122)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'game_id'</li><li>'date'</li><li>'home'</li><li>'away'</li><li>'play_id'</li><li>'half'</li><li>'time_remaining_half'</li><li>'secs_remaining'</li><li>'secs_remaining_absolute'</li><li>'description'</li><li>'action_team'</li><li>'home_score'</li><li>'away_score'</li><li>'score_diff'</li><li>'play_length'</li><li>'scoring_play'</li><li>'foul'</li><li>'win_prob'</li><li>'naive_win_prob'</li><li>'home_time_out_remaining'</li><li>'away_time_out_remaining'</li><li>'home_favored_by'</li><li>'total_line'</li><li>'referees'</li><li>'arena_location'</li><li>'arena'</li><li>'capacity'</li><li>'attendance'</li><li>'shot_x'</li><li>'shot_y'</li><li>'shot_team'</li><li>'shot_outcome'</li><li>'shooter'</li><li>'assist'</li><li>'three_pt'</li><li>'free_throw'</li><li>'possession_before'</li><li>'possession_after'</li><li>'wrong_time'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'game\\_id'\n",
              "\\item 'date'\n",
              "\\item 'home'\n",
              "\\item 'away'\n",
              "\\item 'play\\_id'\n",
              "\\item 'half'\n",
              "\\item 'time\\_remaining\\_half'\n",
              "\\item 'secs\\_remaining'\n",
              "\\item 'secs\\_remaining\\_absolute'\n",
              "\\item 'description'\n",
              "\\item 'action\\_team'\n",
              "\\item 'home\\_score'\n",
              "\\item 'away\\_score'\n",
              "\\item 'score\\_diff'\n",
              "\\item 'play\\_length'\n",
              "\\item 'scoring\\_play'\n",
              "\\item 'foul'\n",
              "\\item 'win\\_prob'\n",
              "\\item 'naive\\_win\\_prob'\n",
              "\\item 'home\\_time\\_out\\_remaining'\n",
              "\\item 'away\\_time\\_out\\_remaining'\n",
              "\\item 'home\\_favored\\_by'\n",
              "\\item 'total\\_line'\n",
              "\\item 'referees'\n",
              "\\item 'arena\\_location'\n",
              "\\item 'arena'\n",
              "\\item 'capacity'\n",
              "\\item 'attendance'\n",
              "\\item 'shot\\_x'\n",
              "\\item 'shot\\_y'\n",
              "\\item 'shot\\_team'\n",
              "\\item 'shot\\_outcome'\n",
              "\\item 'shooter'\n",
              "\\item 'assist'\n",
              "\\item 'three\\_pt'\n",
              "\\item 'free\\_throw'\n",
              "\\item 'possession\\_before'\n",
              "\\item 'possession\\_after'\n",
              "\\item 'wrong\\_time'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'game_id'\n",
              "2. 'date'\n",
              "3. 'home'\n",
              "4. 'away'\n",
              "5. 'play_id'\n",
              "6. 'half'\n",
              "7. 'time_remaining_half'\n",
              "8. 'secs_remaining'\n",
              "9. 'secs_remaining_absolute'\n",
              "10. 'description'\n",
              "11. 'action_team'\n",
              "12. 'home_score'\n",
              "13. 'away_score'\n",
              "14. 'score_diff'\n",
              "15. 'play_length'\n",
              "16. 'scoring_play'\n",
              "17. 'foul'\n",
              "18. 'win_prob'\n",
              "19. 'naive_win_prob'\n",
              "20. 'home_time_out_remaining'\n",
              "21. 'away_time_out_remaining'\n",
              "22. 'home_favored_by'\n",
              "23. 'total_line'\n",
              "24. 'referees'\n",
              "25. 'arena_location'\n",
              "26. 'arena'\n",
              "27. 'capacity'\n",
              "28. 'attendance'\n",
              "29. 'shot_x'\n",
              "30. 'shot_y'\n",
              "31. 'shot_team'\n",
              "32. 'shot_outcome'\n",
              "33. 'shooter'\n",
              "34. 'assist'\n",
              "35. 'three_pt'\n",
              "36. 'free_throw'\n",
              "37. 'possession_before'\n",
              "38. 'possession_after'\n",
              "39. 'wrong_time'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"game_id\"                 \"date\"                   \n",
              " [3] \"home\"                    \"away\"                   \n",
              " [5] \"play_id\"                 \"half\"                   \n",
              " [7] \"time_remaining_half\"     \"secs_remaining\"         \n",
              " [9] \"secs_remaining_absolute\" \"description\"            \n",
              "[11] \"action_team\"             \"home_score\"             \n",
              "[13] \"away_score\"              \"score_diff\"             \n",
              "[15] \"play_length\"             \"scoring_play\"           \n",
              "[17] \"foul\"                    \"win_prob\"               \n",
              "[19] \"naive_win_prob\"          \"home_time_out_remaining\"\n",
              "[21] \"away_time_out_remaining\" \"home_favored_by\"        \n",
              "[23] \"total_line\"              \"referees\"               \n",
              "[25] \"arena_location\"          \"arena\"                  \n",
              "[27] \"capacity\"                \"attendance\"             \n",
              "[29] \"shot_x\"                  \"shot_y\"                 \n",
              "[31] \"shot_team\"               \"shot_outcome\"           \n",
              "[33] \"shooter\"                 \"assist\"                 \n",
              "[35] \"three_pt\"                \"free_throw\"             \n",
              "[37] \"possession_before\"       \"possession_after\"       \n",
              "[39] \"wrong_time\"             "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# what are the column names?\n",
        "colnames(nova2122)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>5399</li><li>39</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 5399\n",
              "\\item 39\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 5399\n",
              "2. 39\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] 5399   39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# this data looks relatively clean, but we want only shooting data\n",
        "# let's get rid of rows where there isn't a shooter\n",
        "# this would be rows where the shooter is NA\n",
        "# such as a turnover, steal, rebound, or block\n",
        "nova2122 <- nova2122 %>%\n",
        "  filter(!is.na(shooter))\n",
        "\n",
        "# let's check the shape of the data\n",
        "dim(nova2122)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can see that we removed about 5,000 rows and are left with just a little over half the initial data\n",
        "\n",
        "# only taking the columns I want from this dataset\n",
        "sample <- nova2122 %>% select(game_id, play_id, half, shooter, shot_outcome, home, away, action_team)\n",
        "\n",
        "#creating a new column shooter_team\n",
        "sample <- sample %>%\n",
        "  mutate(\n",
        "    shooter_team = ifelse(action_team == \"home\", home, away))\n",
        "\n",
        "# Specifying columns to drop and removing them from the dataframe\n",
        "columns_to_drop <- c(\"home\", \"away\", \"action_team\")\n",
        "\n",
        "sample <- sample %>%\n",
        "  select(-one_of(columns_to_drop))\n",
        "\n",
        "#I want to create a previous_shots column that says how many shots the shooter has made or missed in a row before the current shot they are taking\n",
        "sample <- sample %>%\n",
        "  mutate(\n",
        "    shot_outcome_numeric = ifelse(shot_outcome == \"made\", 1, -1)\n",
        "  )\n",
        "\n",
        "sample <- sample %>%\n",
        "  group_by(game_id, half, shooter) %>%\n",
        "  arrange(play_id) %>%\n",
        "  mutate(\n",
        "    shot_sequence = cumsum(shot_outcome_numeric)) %>%\n",
        "  ungroup()\n",
        "\n",
        "sample3 <- sample %>%\n",
        "  mutate(\n",
        "    shot_sequence = ifelse(shot_outcome == \"made\" & shot_sequence <= 0, 1,\n",
        "                  ifelse(shot_outcome == \"missed\" & shot_sequence >= 0, -1, shot_sequence))\n",
        "  )\n",
        "\n",
        "sample3 <- sample3 %>%\n",
        "  group_by(game_id, half, shooter) %>%\n",
        "  arrange(play_id) %>%\n",
        "  mutate(\n",
        "    previous_shots = ifelse(row_number() == 1, 0, lag(shot_sequence, default = 0))\n",
        "  ) %>%\n",
        "  ungroup()\n",
        "\n",
        "write.csv(sample3, file = \"./data/modified_data/nova2122.csv\", row.names = FALSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here is a screen shot of the modified data: \n",
        "<br></br>\n",
        "![modified data](./images/nova2122clean.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2019-20 Season cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# let's load in the data\n",
        "nova1920 <- read.csv('./data/raw_data/villanova1920.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>9581</li><li>39</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 9581\n",
              "\\item 39\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 9581\n",
              "2. 39\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] 9581   39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# let's check the shape of the data\n",
        "dim(nova1920)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>'game_id'</li><li>'date'</li><li>'home'</li><li>'away'</li><li>'play_id'</li><li>'half'</li><li>'time_remaining_half'</li><li>'secs_remaining'</li><li>'secs_remaining_absolute'</li><li>'description'</li><li>'action_team'</li><li>'home_score'</li><li>'away_score'</li><li>'score_diff'</li><li>'play_length'</li><li>'scoring_play'</li><li>'foul'</li><li>'win_prob'</li><li>'naive_win_prob'</li><li>'home_time_out_remaining'</li><li>'away_time_out_remaining'</li><li>'home_favored_by'</li><li>'total_line'</li><li>'referees'</li><li>'arena_location'</li><li>'arena'</li><li>'capacity'</li><li>'attendance'</li><li>'shot_x'</li><li>'shot_y'</li><li>'shot_team'</li><li>'shot_outcome'</li><li>'shooter'</li><li>'assist'</li><li>'three_pt'</li><li>'free_throw'</li><li>'possession_before'</li><li>'possession_after'</li><li>'wrong_time'</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 'game\\_id'\n",
              "\\item 'date'\n",
              "\\item 'home'\n",
              "\\item 'away'\n",
              "\\item 'play\\_id'\n",
              "\\item 'half'\n",
              "\\item 'time\\_remaining\\_half'\n",
              "\\item 'secs\\_remaining'\n",
              "\\item 'secs\\_remaining\\_absolute'\n",
              "\\item 'description'\n",
              "\\item 'action\\_team'\n",
              "\\item 'home\\_score'\n",
              "\\item 'away\\_score'\n",
              "\\item 'score\\_diff'\n",
              "\\item 'play\\_length'\n",
              "\\item 'scoring\\_play'\n",
              "\\item 'foul'\n",
              "\\item 'win\\_prob'\n",
              "\\item 'naive\\_win\\_prob'\n",
              "\\item 'home\\_time\\_out\\_remaining'\n",
              "\\item 'away\\_time\\_out\\_remaining'\n",
              "\\item 'home\\_favored\\_by'\n",
              "\\item 'total\\_line'\n",
              "\\item 'referees'\n",
              "\\item 'arena\\_location'\n",
              "\\item 'arena'\n",
              "\\item 'capacity'\n",
              "\\item 'attendance'\n",
              "\\item 'shot\\_x'\n",
              "\\item 'shot\\_y'\n",
              "\\item 'shot\\_team'\n",
              "\\item 'shot\\_outcome'\n",
              "\\item 'shooter'\n",
              "\\item 'assist'\n",
              "\\item 'three\\_pt'\n",
              "\\item 'free\\_throw'\n",
              "\\item 'possession\\_before'\n",
              "\\item 'possession\\_after'\n",
              "\\item 'wrong\\_time'\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 'game_id'\n",
              "2. 'date'\n",
              "3. 'home'\n",
              "4. 'away'\n",
              "5. 'play_id'\n",
              "6. 'half'\n",
              "7. 'time_remaining_half'\n",
              "8. 'secs_remaining'\n",
              "9. 'secs_remaining_absolute'\n",
              "10. 'description'\n",
              "11. 'action_team'\n",
              "12. 'home_score'\n",
              "13. 'away_score'\n",
              "14. 'score_diff'\n",
              "15. 'play_length'\n",
              "16. 'scoring_play'\n",
              "17. 'foul'\n",
              "18. 'win_prob'\n",
              "19. 'naive_win_prob'\n",
              "20. 'home_time_out_remaining'\n",
              "21. 'away_time_out_remaining'\n",
              "22. 'home_favored_by'\n",
              "23. 'total_line'\n",
              "24. 'referees'\n",
              "25. 'arena_location'\n",
              "26. 'arena'\n",
              "27. 'capacity'\n",
              "28. 'attendance'\n",
              "29. 'shot_x'\n",
              "30. 'shot_y'\n",
              "31. 'shot_team'\n",
              "32. 'shot_outcome'\n",
              "33. 'shooter'\n",
              "34. 'assist'\n",
              "35. 'three_pt'\n",
              "36. 'free_throw'\n",
              "37. 'possession_before'\n",
              "38. 'possession_after'\n",
              "39. 'wrong_time'\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              " [1] \"game_id\"                 \"date\"                   \n",
              " [3] \"home\"                    \"away\"                   \n",
              " [5] \"play_id\"                 \"half\"                   \n",
              " [7] \"time_remaining_half\"     \"secs_remaining\"         \n",
              " [9] \"secs_remaining_absolute\" \"description\"            \n",
              "[11] \"action_team\"             \"home_score\"             \n",
              "[13] \"away_score\"              \"score_diff\"             \n",
              "[15] \"play_length\"             \"scoring_play\"           \n",
              "[17] \"foul\"                    \"win_prob\"               \n",
              "[19] \"naive_win_prob\"          \"home_time_out_remaining\"\n",
              "[21] \"away_time_out_remaining\" \"home_favored_by\"        \n",
              "[23] \"total_line\"              \"referees\"               \n",
              "[25] \"arena_location\"          \"arena\"                  \n",
              "[27] \"capacity\"                \"attendance\"             \n",
              "[29] \"shot_x\"                  \"shot_y\"                 \n",
              "[31] \"shot_team\"               \"shot_outcome\"           \n",
              "[33] \"shooter\"                 \"assist\"                 \n",
              "[35] \"three_pt\"                \"free_throw\"             \n",
              "[37] \"possession_before\"       \"possession_after\"       \n",
              "[39] \"wrong_time\"             "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# what are the column names?\n",
        "colnames(nova1920)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>\n",
              ".list-inline {list-style: none; margin:0; padding: 0}\n",
              ".list-inline>li {display: inline-block}\n",
              ".list-inline>li:not(:last-child)::after {content: \"\\00b7\"; padding: 0 .5ex}\n",
              "</style>\n",
              "<ol class=list-inline><li>4543</li><li>39</li></ol>\n"
            ],
            "text/latex": [
              "\\begin{enumerate*}\n",
              "\\item 4543\n",
              "\\item 39\n",
              "\\end{enumerate*}\n"
            ],
            "text/markdown": [
              "1. 4543\n",
              "2. 39\n",
              "\n",
              "\n"
            ],
            "text/plain": [
              "[1] 4543   39"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# this data looks relatively clean, but we want only shooting data\n",
        "# let's get rid of rows where there isn't a shooter\n",
        "# this would be rows where the shooter is NA\n",
        "# such as a turnover, steal, rebound, or block\n",
        "nova1920 <- nova1920 %>%\n",
        "  filter(!is.na(shooter))\n",
        "\n",
        "# let's check the shape of the data\n",
        "dim(nova1920)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# we can see that we removed about 5,000 rows and are left with just a little over half the initial data\n",
        "\n",
        "# only taking the columns I want from this dataset\n",
        "sample <- nova1920 %>% select(game_id, play_id, half, shooter, shot_outcome, home, away, action_team)\n",
        "\n",
        "#creating a new column shooter_team\n",
        "sample <- sample %>%\n",
        "  mutate(\n",
        "    shooter_team = ifelse(action_team == \"home\", home, away))\n",
        "\n",
        "# Specifying columns to drop and removing them from the dataframe\n",
        "columns_to_drop <- c(\"home\", \"away\", \"action_team\")\n",
        "\n",
        "sample <- sample %>%\n",
        "  select(-one_of(columns_to_drop))\n",
        "\n",
        "#I want to create a previous_shots column that says how many shots the shooter has made or missed in a row before the current shot they are taking\n",
        "sample <- sample %>%\n",
        "  mutate(\n",
        "    shot_outcome_numeric = ifelse(shot_outcome == \"made\", 1, -1)\n",
        "  )\n",
        "\n",
        "sample <- sample %>%\n",
        "  group_by(game_id, half, shooter) %>%\n",
        "  arrange(play_id) %>%\n",
        "  mutate(\n",
        "    shot_sequence = cumsum(shot_outcome_numeric)) %>%\n",
        "  ungroup()\n",
        "\n",
        "sample3 <- sample %>%\n",
        "  mutate(\n",
        "    shot_sequence = ifelse(shot_outcome == \"made\" & shot_sequence <= 0, 1,\n",
        "                  ifelse(shot_outcome == \"missed\" & shot_sequence >= 0, -1, shot_sequence))\n",
        "  )\n",
        "\n",
        "sample3 <- sample3 %>%\n",
        "  group_by(game_id, half, shooter) %>%\n",
        "  arrange(play_id) %>%\n",
        "  mutate(\n",
        "    previous_shots = ifelse(row_number() == 1, 0, lag(shot_sequence, default = 0))\n",
        "  ) %>%\n",
        "  ungroup()\n",
        "\n",
        "write.csv(sample3, file = \"./data/modified_data/nova1920.csv\", row.names = FALSE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# reddit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# newsapi\n",
        "\n",
        "let's clean this using python:\n",
        "<br></br>\n",
        "here is a picture of the first few rows of the raw data:\n",
        "<br></br>\n",
        "![raw data](./images/newsapi.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reading in the file\n",
        "newsapi = pd.read_csv('./data/raw_data/newsapi.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 4)"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what is the shape of this data\n",
        "newsapi.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['0', '1', '2', '3'], dtype='object')"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# what are the column names\n",
        "newsapi.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/williammcgloin/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/williammcgloin/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to\n",
            "[nltk_data]     /Users/williammcgloin/nltk_data...\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Initialize the Lemmatizer and stopwords list\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    # Remove special characters and numbers\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    \n",
        "    # Tokenization and lowercase\n",
        "    words = text.lower().split()\n",
        "    \n",
        "    # Remove stopwords and apply lemmatization\n",
        "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
        "    \n",
        "    return ' '.join(words)\n",
        "\n",
        "# Apply preprocessing to the 'text' column\n",
        "newsapi['cleaned_text'] = newsapi['2'].apply(preprocess_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0]]\n"
          ]
        }
      ],
      "source": [
        "# Initialize the CountVectorizer\n",
        "count_vectorizer = CountVectorizer()\n",
        "\n",
        "# Fit and transform the preprocessed text data\n",
        "X = count_vectorizer.fit_transform(newsapi['cleaned_text'])\n",
        "\n",
        "# printing part of the sparse matrix\n",
        "print(X[:20, :20].toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   0    1    2    3    4    5    6    7    8    9    ...  539  540  541  542  \\\n",
            "0    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "1    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "2    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "3    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "4    0    0    0    0    0    0    0    0    0    0  ...    0    0    0    0   \n",
            "\n",
            "   543  544  545  546  547  548  \n",
            "0    0    0    0    0    0    0  \n",
            "1    0    0    0    0    0    0  \n",
            "2    0    0    0    0    0    0  \n",
            "3    0    0    0    0    0    0  \n",
            "4    0    0    0    0    0    0  \n",
            "\n",
            "[5 rows x 549 columns]\n"
          ]
        }
      ],
      "source": [
        "# Convert the sparse matrix to a Pandas DataFrame\n",
        "X_df = pd.DataFrame(X.toarray())\n",
        "\n",
        "# Display the first few rows of the DataFrame\n",
        "print(X_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['abnormality' 'abound' 'ac' 'acc' 'action' 'advice' 'aew' 'ahead' 'al'\n",
            " 'alds' 'alert' 'already' 'alyssa' 'amid' 'andy' 'angelos' 'another'\n",
            " 'answer' 'apple' 'argentina' 'arizona' 'arkansas' 'armondo' 'arsenal'\n",
            " 'astonishing' 'austin' 'back' 'balogun' 'ban' 'baseball' 'battle' 'bear'\n",
            " 'bearcat' 'beat' 'beaten' 'become' 'becoming' 'behind' 'belief'\n",
            " 'bellingham' 'bengal' 'besides' 'best' 'bet' 'better' 'beyond' 'big'\n",
            " 'biggs' 'bird' 'blount' 'blue' 'blunder' 'bonus' 'booing' 'booking'\n",
            " 'boston' 'bottom' 'brad' 'brain' 'brave' 'breaking' 'breanna' 'brewer'\n",
            " 'buccaneer' 'building' 'bukayo' 'bumper' 'call' 'candidate' 'cant' 'card'\n",
            " 'cardinal' 'cargill' 'carlos' 'case' 'casino' 'catch' 'central' 'cfb'\n",
            " 'champion' 'charge' 'chicago' 'christian' 'cincinnati' 'city' 'climate'\n",
            " 'clinch' 'close' 'closer' 'clue' 'clutch' 'coach' 'coaching'\n",
            " 'cockeysville' 'college' 'colorado' 'column' 'come' 'coming' 'commander'\n",
            " 'commits' 'comparison' 'complete' 'concern' 'conference' 'contender'\n",
            " 'corner' 'could' 'cover' 'coverage' 'cowboy' 'cpa' 'craziness' 'crazy'\n",
            " 'crop' 'crowd' 'cub' 'cup' 'dalton' 'dame' 'daniel' 'david' 'debut'\n",
            " 'defense' 'deion' 'delight' 'deserved' 'desmond' 'desperate' 'despite'\n",
            " 'division' 'dolphin' 'doubleheader' 'draw' 'driven' 'drought' 'duck'\n",
            " 'duke' 'dy' 'eagle' 'earns' 'eberflus' 'edge' 'emerges' 'end' 'enter'\n",
            " 'episode' 'er' 'europe' 'evaluation' 'even' 'event' 'ever' 'everywhere'\n",
            " 'evokes' 'excited' 'exit' 'expert' 'eye' 'fact' 'fade' 'falcon' 'famu'\n",
            " 'fantasy' 'father' 'favored' 'favorite' 'fiba' 'field' 'fighter'\n",
            " 'fighting' 'final' 'fire' 'fired' 'first' 'five' 'fix' 'fiziev' 'fizzle'\n",
            " 'florida' 'flyweight' 'focus' 'folarin' 'football' 'force' 'form' 'found'\n",
            " 'franklin' 'game' 'gamrot' 'gen' 'giant' 'goal' 'god' 'goff' 'going'\n",
            " 'good' 'got' 'grade' 'grasso' 'guez' 'ham' 'hardy' 'harsh' 'head' 'heat'\n",
            " 'heavily' 'here' 'hero' 'highlight' 'hit' 'home' 'honor' 'hot' 'huge'\n",
            " 'hurricane' 'hype' 'image' 'infamous' 'injures' 'issue' 'ja' 'jack'\n",
            " 'jade' 'jay' 'jet' 'jimmy' 'john' 'join' 'jones' 'journey' 'jr' 'jude'\n",
            " 'julio' 'justin' 'kansa' 'keep' 'kelce' 'key' 'king' 'knee' 'knockout'\n",
            " 'larger' 'laugh' 'leaf' 'league' 'learned' 'life' 'line' 'lion' 'lionel'\n",
            " 'live' 'livestream' 'locked' 'lofty' 'logan' 'look' 'loose' 'loser'\n",
            " 'loses' 'losing' 'loss' 'lsu' 'lucas' 'madrid' 'mailbag' 'main' 'make'\n",
            " 'makeover' 'man' 'manager' 'manchester' 'marquee' 'maryland' 'match'\n",
            " 'mateusz' 'matt' 'matter' 'mature' 'meeting' 'megan' 'messi' 'miami'\n",
            " 'middleweight' 'milan' 'mlb' 'mojo' 'moment' 'monday' 'morning' 'move'\n",
            " 'must' 'mvp' 'nailed' 'napoli' 'nbas' 'near' 'network' 'new' 'newcastle'\n",
            " 'nfl' 'night' 'noche' 'normal' 'notify' 'notre' 'nowhere' 'number' 'nwsl'\n",
            " 'nycs' 'nz' 'odds' 'ode' 'offense' 'ohio' 'oklahoma' 'onuachu' 'opponent'\n",
            " 'option' 'oregon' 'oriole' 'padre' 'panther' 'pass' 'pat' 'patriot'\n",
            " 'penn' 'penultimate' 'perfect' 'peter' 'phillies' 'philly' 'pick'\n",
            " 'pirate' 'play' 'player' 'playing' 'playoff' 'plenty' 'plus' 'point'\n",
            " 'politics' 'pool' 'pound' 'power' 'prediction' 'pretender' 'preview'\n",
            " 'previewing' 'problem' 'prop' 'provides' 'pulisic' 'purdy' 'question'\n",
            " 'race' 'racer' 'racing' 'rafael' 'ram' 'ranger' 'ranking' 'rapinoe' 'ray'\n",
            " 'read' 'real' 'recap' 'record' 'recruit' 'red' 'regular' 'reign' 'relish'\n",
            " 'remain' 'removed' 'report' 'resident' 'retro' 'return' 'review' 'revved'\n",
            " 'ridder' 'ripe' 'rise' 'river' 'rock' 'rodon' 'rodr' 'rome' 'ross'\n",
            " 'rumor' 'run' 'running' 'ryder' 'saka' 'sander' 'say' 'schedule' 'score'\n",
            " 'sean' 'search' 'season' 'seat' 'sec' 'secure' 'sends' 'sept' 'series'\n",
            " 'served' 'shadow' 'shanahan' 'shevchenko' 'shift' 'show' 'showdown'\n",
            " 'since' 'skid' 'slate' 'smack' 'snap' 'sold' 'someone' 'sooner' 'sox'\n",
            " 'special' 'speed' 'spiro' 'sport' 'spot' 'spotlight' 'spread' 'st'\n",
            " 'stamp' 'stand' 'star' 'start' 'starting' 'state' 'station' 'stats'\n",
            " 'stay' 'stellar' 'stewart' 'stoppage' 'straight' 'strategy' 'streak'\n",
            " 'stream' 'strickland' 'struggling' 'success' 'summer' 'survivor'\n",
            " 'suwinski' 'suzuki' 'sv' 'sweep' 'swift' 'tailspin' 'take' 'takeaway'\n",
            " 'taking' 'tale' 'talking' 'tape' 'taylor' 'tcu' 'team' 'ten' 'test'\n",
            " 'texas' 'theater' 'thing' 'think' 'thirteen' 'thomas' 'thought' 'three'\n",
            " 'thriller' 'thursday' 'tight' 'time' 'title' 'tko' 'tnf' 'today' 'tom'\n",
            " 'top' 'total' 'tournament' 'trail' 'transformation' 'travis' 'trea'\n",
            " 'trojan' 'troy' 'trust' 'trying' 'tssaa' 'turkey' 'turner' 'tv' 'twin'\n",
            " 'two' 'ucf' 'ufc' 'unbeatable' 'unbeaten' 'united' 'unsung' 'upset'\n",
            " 'upside' 'usc' 'usmnt' 'uwf' 'vega' 'veloudos' 'video' 'view' 'vlad'\n",
            " 'wagon' 'warm' 'watch' 'watching' 'week' 'weekend' 'welcome' 'well'\n",
            " 'went' 'white' 'whitner' 'wild' 'wildcat' 'williams' 'wilson' 'win'\n",
            " 'winner' 'winning' 'wnba' 'woman' 'world' 'wr' 'wrong' 'wwe' 'yahoo'\n",
            " 'yankee' 'year' 'yet' 'youth']\n"
          ]
        }
      ],
      "source": [
        "vocab = count_vectorizer.get_feature_names_out()\n",
        "\n",
        "print(vocab)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### News API cleaning pt. ii"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#reading in the file\n",
        "news_api_2 = pd.read_csv('./data/raw_data/newsapi_2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/williammcgloin/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'list' object has no attribute 'encode'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[1;32m/Users/williammcgloin/Documents/Georgetown/Data Science and Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb Cell 34\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y104sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(hotstreak_list)):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y104sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     text \u001b[39m=\u001b[39m hotstreak_list[i]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y104sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     score \u001b[39m=\u001b[39m sia\u001b[39m.\u001b[39;49mpolarity_scores(text)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y104sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# Label as \"bad\" if the compound score is <= 0.5\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y104sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m score[\u001b[39m'\u001b[39m\u001b[39mcompound\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:361\u001b[0m, in \u001b[0;36mSentimentIntensityAnalyzer.polarity_scores\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    355\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[39mReturn a float for sentiment strength based on the input text.\u001b[39;00m\n\u001b[1;32m    357\u001b[0m \u001b[39mPositive values are positive valence, negative value are negative\u001b[39;00m\n\u001b[1;32m    358\u001b[0m \u001b[39mvalence.\u001b[39;00m\n\u001b[1;32m    359\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[39m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001b[39;00m\n\u001b[0;32m--> 361\u001b[0m sentitext \u001b[39m=\u001b[39m SentiText(\n\u001b[1;32m    362\u001b[0m     text, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mPUNC_LIST, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconstants\u001b[39m.\u001b[39;49mREGEX_REMOVE_PUNCTUATION\n\u001b[1;32m    363\u001b[0m )\n\u001b[1;32m    364\u001b[0m sentiments \u001b[39m=\u001b[39m []\n\u001b[1;32m    365\u001b[0m words_and_emoticons \u001b[39m=\u001b[39m sentitext\u001b[39m.\u001b[39mwords_and_emoticons\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:270\u001b[0m, in \u001b[0;36mSentiText.__init__\u001b[0;34m(self, text, punc_list, regex_remove_punctuation)\u001b[0m\n\u001b[1;32m    268\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, text, punc_list, regex_remove_punctuation):\n\u001b[1;32m    269\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(text, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 270\u001b[0m         text \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(text\u001b[39m.\u001b[39;49mencode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[1;32m    271\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtext \u001b[39m=\u001b[39m text\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mPUNC_LIST \u001b[39m=\u001b[39m punc_list\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
          ]
        }
      ],
      "source": [
        "#hotstreak_dict = news_api_2.to_dict(orient='records')\n",
        "hotstreak_list = news_api_2.values.tolist()\n",
        "\n",
        "\n",
        "import nltk\n",
        "nltk.download('vader_lexicon')  # Download the VADER sentiment lexicon\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "text_list = []\n",
        "label = []\n",
        "sentiment_pos = []\n",
        "\n",
        "for i in range(len(hotstreak_list)):\n",
        "    text = hotstreak_list[i]\n",
        "    score = sia.polarity_scores(text)\n",
        "    \n",
        "    # Label as \"bad\" if the compound score is <= 0.5\n",
        "    if score['compound'] <= 0.5:\n",
        "        label.append(\"bad\")\n",
        "    \n",
        "    # Label as \"good\" if the compound score is > 0.5\n",
        "    else:\n",
        "        label.append(\"good\")\n",
        "\n",
        "    text_list.append(text)\n",
        "    sentiment_pos.append(score['pos'])\n",
        "\n",
        "sentiment_analysis = pd.DataFrame({'text': text_list, 'label': label, 'sentiment_pos': sentiment_pos})\n",
        "print(sentiment_analysis.tail())\n",
        "\n",
        "\n",
        "#sentiment_analysis.to_csv('sentiment.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package vader_lexicon to\n",
            "[nltk_data]     /Users/williammcgloin/nltk_data...\n",
            "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "'ellipsis' object is not subscriptable",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32m/Users/williammcgloin/Documents/Georgetown/Data Science and Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb Cell 35\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y106sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m sentiment_pos \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y106sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mfor\u001b[39;00m text \u001b[39min\u001b[39;00m hotstreak_list:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y106sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     score \u001b[39m=\u001b[39m sia\u001b[39m.\u001b[39mpolarity_scores(text[\u001b[39m1\u001b[39;49m])  \u001b[39m# Use the description (index 1) from the list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y106sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     text_list\u001b[39m.\u001b[39mappend(text[\u001b[39m1\u001b[39m])  \u001b[39m# Append the description to the text_list\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/williammcgloin/Documents/Georgetown/Data%20Science%20and%20Analytics/dsan-5000-project-wmcgloin/website/data-cleaning.ipynb#Y106sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# Label as \"bad\" if the compound score is <= 0.5\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'ellipsis' object is not subscriptable"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('vader_lexicon')  # Download the VADER sentiment lexicon\n",
        "from nltk.sentiment import SentimentIntensityAnalyzer\n",
        "import pandas as pd\n",
        "\n",
        "sia = SentimentIntensityAnalyzer()\n",
        "\n",
        "\n",
        "hotstreak_list = [['Title 1', 'Description 1'], ['Title 2', 'Description 2'], ...]\n",
        "\n",
        "text_list = []\n",
        "label = []\n",
        "sentiment_pos = []\n",
        "\n",
        "for text in hotstreak_list:\n",
        "    score = sia.polarity_scores(text[1])  # Use the description (index 1) from the list\n",
        "    text_list.append(text[1])  # Append the description to the text_list\n",
        "\n",
        "    # Label as \"bad\" if the compound score is <= 0.5\n",
        "    if score['compound'] <= 0.5:\n",
        "        label.append(\"bad\")\n",
        "    \n",
        "    # Label as \"good\" if the compound score is > 0.5\n",
        "    else:\n",
        "        label.append(\"good\")\n",
        "\n",
        "sentiment_analysis = pd.DataFrame({'text': text_list, 'label': label})\n",
        "print(sentiment_analysis.tail())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# individual player data\n",
        "\n",
        "let's clean the aaron judge game data with python:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here is a screen shot of the first few rows of the raw data:\n",
        "<br></br>\n",
        "![raw data](./images/judge2.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reading in the file\n",
        "aaronjudge = pd.read_csv('./data/raw_data/AaronJudgeData.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(111, 37)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#how many rows are in this dataset?\n",
        "aaronjudge.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Team', 'Opp', 'BO', 'Pos', 'PA', 'H', '2B', '3B', 'HR', 'R',\n",
              "       'RBI', 'SB', 'CS', 'BB%', 'K%', 'ISO', 'BABIP', 'EV', 'AVG', 'OBP',\n",
              "       'SLG', 'wOBA', 'wRC+', 'Date.1', 'Team.1', 'Opp.1', 'BO.1', 'Pos.1',\n",
              "       'Events', 'EV.1', 'maxEV', 'LA', 'Barrels', 'Barrel%', 'HardHit',\n",
              "       'HardHit%'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#what are the column names?\n",
        "aaronjudge.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Date', 'Team', 'Opp', 'BO', 'Pos', 'PA', 'H', '2B', '3B', 'HR', 'R',\n",
              "       'RBI', 'SB', 'CS', 'BB%', 'K%', 'ISO', 'BABIP', 'EV', 'AVG', 'OBP',\n",
              "       'SLG', 'wOBA', 'wRC+', 'Events', 'EV.1', 'maxEV', 'LA', 'Barrels',\n",
              "       'Barrel%', 'HardHit', 'HardHit%'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#removing the repeated columns\n",
        "columns_to_remove = ['Date.1', 'Team.1', 'Opp.1', 'BO.1', 'Pos.1']\n",
        "aaronjudge.drop(columns=columns_to_remove, inplace=True)\n",
        "aaronjudge.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "5\n"
          ]
        }
      ],
      "source": [
        "# i belive the initial row with the column names is repeated throughou the data. let's check\n",
        "print((aaronjudge['Date'] == 'Date').sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(106, 32)"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let's remove these rows and then check the shape again\n",
        "aaronjudge.drop(aaronjudge[aaronjudge['Date'] == 'Date'].index, inplace=True)\n",
        "aaronjudge.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(105, 32)"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# there is also a total row which I want to remove as well. let's do that now\n",
        "aaronjudge.drop(aaronjudge[aaronjudge['Date'] == 'Total'].index, inplace=True)\n",
        "aaronjudge.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "home    53\n",
            "away    52\n",
            "Name: location, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# so far, I have removed 6 rows and 5 columns. \n",
        "\n",
        "# I want to create a \"location\" column based on the \"@\" in the \"Opp\" column\n",
        "aaronjudge['location'] = aaronjudge['Opp'].apply(lambda x: 'away' if '@' in x else 'home')\n",
        "\n",
        "# Remove the \"@\" symbol from the values in the \"Opp\" column\n",
        "aaronjudge['Opp'] = aaronjudge['Opp'].str.replace('@', '')\n",
        "\n",
        "# check value counts of the new \"location\" column\n",
        "print(aaronjudge['location'].value_counts()) #this seems accurate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object\n",
            "object\n"
          ]
        }
      ],
      "source": [
        "print(aaronjudge['PA'].dtype)\n",
        "print(aaronjudge['BB%'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.4857333333333336\n",
            "4.314285714285714\n"
          ]
        }
      ],
      "source": [
        "# I want to create two new columns. The number of at bats per each game and the number of hard hits in each game. \n",
        "# for this project, we are going to calculate at-bats as should be the number of plate appearances minus walks (sacrifices and HBP are not included in this dataset)\n",
        "\n",
        "#first i have to remove the '%' symbol and convert 'BB%' to a float\n",
        "\n",
        "aaronjudge['BB%'] = aaronjudge['BB%'].astype(str)\n",
        "aaronjudge['BB%'] = aaronjudge['BB%'].str.rstrip('%').astype(float) / 100.0\n",
        "\n",
        "# Round the 'BB%' column to three decimal places\n",
        "aaronjudge['BB%'] = aaronjudge['BB%'].round(3)\n",
        "\n",
        "#print(aaronjudge['BB%'].mean())\n",
        "\n",
        "#convert 'PA' to a float\n",
        "aaronjudge['PA'] = aaronjudge['PA'].astype(float)\n",
        "\n",
        "# now I can create the new at_bats column\n",
        "aaronjudge['at_bats'] = aaronjudge['PA'] * (1 - aaronjudge['BB%'])\n",
        "\n",
        "#now lets see the average number of at bats vs the average number of plate appearances\n",
        "print(aaronjudge['at_bats'].mean())\n",
        "print(aaronjudge['PA'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "object\n",
            "object\n"
          ]
        }
      ],
      "source": [
        "# now I want to create a new column for hard hits per game\n",
        "# we can do this by multiplying the hard hit percentage by the events column (these columns were part of a different table that was merged with the original table)\n",
        "\n",
        "print(aaronjudge['HardHit%'].dtype)\n",
        "print(aaronjudge['Events'].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.52\n"
          ]
        }
      ],
      "source": [
        "# this code is very similar to what we just did\n",
        "\n",
        "#first i have to remove the '%' symbol and convert 'HardHit%' to a float\n",
        "\n",
        "aaronjudge['HardHit%'] = aaronjudge['HardHit%'].astype(str)\n",
        "aaronjudge['HardHit%'] = aaronjudge['HardHit%'].str.rstrip('%').astype(float) / 100.0\n",
        "\n",
        "# Round the 'HardHit%' column to three decimal places\n",
        "aaronjudge['HardHit%'] = aaronjudge['HardHit%'].round(3)\n",
        "\n",
        "#print(aaronjudge['HardHit%'].mean())\n",
        "\n",
        "#convert 'Events' to a float\n",
        "aaronjudge['Events'] = aaronjudge['Events'].astype(float)\n",
        "\n",
        "# now I can create the new hard_hits column\n",
        "aaronjudge['hard_hits'] = (aaronjudge['Events'] * aaronjudge['HardHit%']).round(0)\n",
        "\n",
        "#now lets see the average number of hard_hits per game\n",
        "print(aaronjudge['hard_hits'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.42829999999999996\n"
          ]
        }
      ],
      "source": [
        "# finally, let's create a correct hardhit% column that is based on the number of at-bats, not the number of times a player puts the ball in play\n",
        "aaronjudge['correct_hardhit%'] = (aaronjudge['hard_hits'] / aaronjudge['at_bats']).round(2)\n",
        "\n",
        "# now let's see the average correct hardhit% for Aaron Judge\n",
        "print(aaronjudge['correct_hardhit%'].mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100, 36)"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# sometimes in certain stadiums or based on the weather, the HardHit% data is missing\n",
        "# this causes the value of the new correct_hardhit% column to be NaN, so let's remove those few rows\n",
        "aaronjudge.dropna(subset=['correct_hardhit%'], inplace=True)\n",
        "\n",
        "#let's check the shape again\n",
        "aaronjudge.shape #loss of 5 rows"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "# now we can save this to a csv file\n",
        "aaronjudge.to_csv('./data/modified_data/aaronjudge.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "here is a screenshot of the first couple rows of the modified csv file:\n",
        "<br></br>\n",
        "![Clean Data](./images/aaron_judge_clean.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Extra Joke\n",
        "\n",
        "What did the broom say to the vacuum?\n",
        "\n",
        "“I’m so tired of people pushing us around.”\n",
        "<br></br>\n",
        "![Figure 1](./images/broom-water-buckets.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "# trying something out \n",
        "import pandas as pd\n",
        "\n",
        "# Load the sentiment scores from the JSON file\n",
        "with open('sentiment_scores.json', 'r') as json_file:\n",
        "    sentiment_scores = json.load(json_file)\n",
        "\n",
        "# Create lists to store data\n",
        "titles = []  # List to store document titles\n",
        "descriptions = []   # List to store document descriptions\n",
        "sentiment_labels = []  # List to store sentiment labels\n",
        "\n",
        "# Extract the scores, titles, descriptions, and labels\n",
        "for idx, item in enumerate(sentiment_scores, start=1):\n",
        "    titles.append(item.get('title', ''))  # Get the title of the document\n",
        "    descriptions.append(item.get('description', ''))    # Get the description of the document\n",
        "    sentiment_score = item.get('sentiment_score', {})\n",
        "    \n",
        "    # Determine the sentiment label based on the compound score\n",
        "    if sentiment_score.get('compound', 0) > 0:\n",
        "        sentiment_labels.append('positive')\n",
        "    elif sentiment_score.get('compound', 0) == 0:\n",
        "        sentiment_labels.append('neutral')\n",
        "    else:\n",
        "        sentiment_labels.append('negative')\n",
        "\n",
        "# Create a DataFrame\n",
        "data = {\n",
        "    'Title': titles,\n",
        "    'Description': descriptions,\n",
        "    'Sentiment Label': sentiment_labels\n",
        "}\n",
        "\n",
        "df_with_labels = pd.DataFrame(data)\n",
        "\n",
        "df_with_labels.head()\n",
        "\n",
        "# Save to CSV\n",
        "df_with_labels.to_csv('./data/modified_data/sentiment_scores_with_titles.csv', index=False)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
